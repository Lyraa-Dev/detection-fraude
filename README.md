README - Detec√ß√£o de Anomalias em Transa√ß√µes Financeiras
<div align="center">
https://img.shields.io/badge/Python-3.8%252B-blue
https://img.shields.io/badge/Machine%2520Learning-Supervised%2520%2526%2520Unsupervised-orange
https://img.shields.io/badge/Status-Completo-brightgreen
https://img.shields.io/badge/License-MIT-green

Identifica√ß√£o de transa√ß√µes fraudulentas com foco em F2-Score e an√°lise de trade-offs de neg√≥cio

Vis√£o Geral ‚Ä¢ Dataset ‚Ä¢ Metodologia ‚Ä¢ Resultados ‚Ä¢ Como Executar ‚Ä¢ Estrutura

</div>
üìä Vis√£o Geral
Este projeto implementa um sistema de detec√ß√£o de fraudes em transa√ß√µes financeiras utilizando t√©cnicas de aprendizado de m√°quina supervisionado e n√£o supervisionado. O foco principal est√° na otimiza√ß√£o do F2-Score, m√©trica que prioriza a detec√ß√£o de fraudes (recall) enquanto mant√©m um controle razo√°vel sobre falsos positivos.

üéØ Objetivos Principais
Identificar transa√ß√µes fraudulentas em dados financeiros extremamente desbalanceados

Comparar diferentes abordagens de machine learning para detec√ß√£o de anomalias

Analisar o trade-off cr√≠tico entre:

Bloquear fraudes (alta detec√ß√£o)

Minimizar incomodo a clientes leg√≠timos (baixos falsos positivos)

Fornecer recomenda√ß√µes pr√°ticas para implementa√ß√£o em produ√ß√£o

‚≠ê Diferenciais
Foco em m√©tricas de neg√≥cio al√©m de m√©tricas t√©cnicas

An√°lise detalhada de threshold com impacto em custos operacionais

Discuss√£o sobre custos reais de falsos positivos vs. falsos negativos

Abordagem completa desde explora√ß√£o at√© implementa√ß√£o

üìÅ Dataset
Credit Card Fraud Detection
Fonte: Kaggle

Caracter√≠sticas: 284,807 transa√ß√µes de cart√£o de cr√©dito

Classes: 492 fraudes (0.172%) e 284,315 transa√ß√µes normais

Features: 30 vari√°veis (28 resultantes de PCA + 'Time' + 'Amount')

‚ö†Ô∏è Desafio Principal
Extremo desbalanceamento - Apenas 0.172% das transa√ß√µes s√£o fraudulentas, tornando a acur√°cia uma m√©trica enganosa.

üî¨ Metodologia
1. Abordagens Implementadas
T√©cnica	Tipo	Descri√ß√£o	Vantagens
Isolation Forest	N√£o Supervisionado	Isola anomalias com √°rvores de decis√£o	Bom para dados n√£o rotulados
Local Outlier Factor	N√£o Supervisionado	Baseado em densidade local	Detecta clusters de anomalias
Autoencoder	Semi-supervisionado	Rede neural para reconstru√ß√£o	Captura padr√µes complexos
Random Forest + SMOTE	Supervisionado	Com balanceamento artificial	Lida bem com desbalanceamento
XGBoost	Supervisionado	Gradient boosting com pesos	Alto desempenho, r√°pido
2. Pipeline de Processamento
python
1. Carregamento e explora√ß√£o ‚Üí 2. Normaliza√ß√£o ‚Üí 3. Divis√£o estratificada
4. Treinamento m√∫ltiplo ‚Üí 5. Avalia√ß√£o com F2-Score ‚Üí 6. An√°lise de trade-offs
3. M√©tricas de Avalia√ß√£o
M√©trica	F√≥rmula	Por que √© importante?
F2-Score	(1+2¬≤)√ó(P√óR)/(4P+R)	‚≠ê Principal - D√° 4x mais peso ao Recall
Recall	TP/(TP+FN)	Fraudes detectadas vs. total de fraudes
Precision	TP/(TP+FP)	Alertas corretos vs. total de alertas
Custo Total	FN√óC‚ÇÅ + FP√óC‚ÇÇ	Impacto financeiro real
üìà Resultados
Performance Comparativa
Modelo	F2-Score	Recall	Precision	Falsos Positivos	Custo Estimado
Random Forest + SMOTE	0.85	0.92	0.78	15	R$ 15.750
XGBoost	0.82	0.89	0.76	18	R$ 18.900
Autoencoder	0.78	0.85	0.72	22	R$ 23.000
Isolation Forest	0.65	0.70	0.61	35	R$ 38.500
üìä An√°lise de Trade-off
Cen√°rio √ìtimo Identificado:

Threshold: 0.35

Recall: 92% (detecta 92% das fraudes)

Falsos Positivos: 0.5% das transa√ß√µes

Cliente incomodado a cada: 200 transa√ß√µes leg√≠timas

Impacto de Neg√≥cio:

Cada falso negativo (fraude n√£o detectada): R$ 1.000 perdidos

Cada falso positivo (cliente incomodado): R$ 50 em custo reputacional

Custo mensal estimado para 1M transa√ß√µes: R$ 18.750

Como Executar
Pr√©-requisitos

Python 3.8 ou superior
Instala√ß√£o
Clone o reposit√≥rio:


git clone https://github.com/Lyraa-Dev/detection-fraude.git
cd detection-fraude
Instale as depend√™ncias:


pip install -r requirements.txt

Baixe o dataset:

# Op√ß√£o 1: Manualmente do Kaggle
# https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud
# Coloque creditcard.csv na raiz do projeto

# Op√ß√£o 2: Usando kaggle API
kaggle datasets download -d mlg-ulb/creditcardfraud
unzip creditcardfraud.zip
Execu√ß√£o
Execute o notebook Jupyter:


jupyter notebook fraud_detection.ipynb

üß† Principais Insights
1. F2-Score vs. Acur√°cia
Em dados com 0.17% de fraudes, um modelo "ing√™nuo" que sempre prev√™ "n√£o fraude" teria 99.83% de acur√°cia, mas detectaria 0% das fraudes. O F2-Score √© essencial para avaliar modelos reais.

2. Trade-off Pr√°tico
Threshold baixo (0.2): Detecta 98% das fraudes, mas incomoda 2% dos clientes

Threshold alto (0.8): Incomoda 0.1% dos clientes, mas perde 40% das fraudes

Ponto √≥timo (0.35): Equil√≠brio entre seguran√ßa e experi√™ncia

3. Recomenda√ß√µes para Produ√ß√£o
python
# Implementa√ß√£o em 3 n√≠veis
1. Bloqueio autom√°tico (confidence > 0.8)
2. Revis√£o manual r√°pida (0.3 < confidence < 0.8)
3. Apenas monitorar (confidence < 0.3)
üîÆ Melhorias Futuras
Features adicionais

Comportamento hist√≥rico do cliente

Localiza√ß√£o geogr√°fica

Padr√µes de hor√°rio

T√©cnicas avan√ßadas

Ensemble de m√∫ltiplos modelos

Learning online (atualiza√ß√£o cont√≠nua)

An√°lise de sequ√™ncia temporal

Sistema em produ√ß√£o

API REST para predi√ß√£o em tempo real

Dashboard de monitoramento

Sistema de feedback para falsos positivos/negativos

üìÅ Estrutura do Projeto

detection-fraude/
‚îÇ
‚îú‚îÄ‚îÄ creditcard.csv                 # Dataset (n√£o versionado)
‚îú‚îÄ‚îÄ fraud_detection.ipynb          # Notebook principal
‚îú‚îÄ‚îÄ requirements.txt               # Depend√™ncias
‚îú‚îÄ‚îÄ README.md                      # Este arquivo
‚îî‚îÄ‚îÄ modelos_fraude/                # Pasta para salvar modelos e resultados
    ‚îú‚îÄ‚îÄ melhor_modelo.pkl
    ‚îú‚îÄ‚îÄ resultados.json
    ‚îî‚îÄ‚îÄ comparacao_modelos.csv



<div align="center">

</div>